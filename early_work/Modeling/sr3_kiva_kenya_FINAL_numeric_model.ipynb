{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "\n",
    "#modeling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "kiva = pd.read_csv('kivasmall.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(419156, 29)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kiva.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables of interest: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51170, 29)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kivake = kiva[kiva['COUNTRY_CODE']=='KE']\n",
    "kivake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LOAN_ID                  0\n",
       "ORIGINAL_LANGUAGE     1144\n",
       "LOAN_AMOUNT              0\n",
       "STATUS                   0\n",
       "ACTIVITY_NAME            0\n",
       "SECTOR_NAME              0\n",
       "COUNTRY_CODE             0\n",
       "LENDER_TERM              0\n",
       "REPAYMENT_INTERVAL       0\n",
       "DISTRIBUTION_MODEL       0\n",
       "word_count_DT            0\n",
       "word_count_TAGS          0\n",
       "word_count_LU            0\n",
       "char_count_DT            0\n",
       "char_count_TAGS          0\n",
       "char_count_LU            0\n",
       "month                    0\n",
       "FEM_COUNT             1144\n",
       "MALE_COUNT            1144\n",
       "PIC_TRUE_COUNT        1144\n",
       "PIC_FALSE_COUNT       1144\n",
       "ANY_FEM               1144\n",
       "ANY_MALE              1144\n",
       "word_char_DT             0\n",
       "word_char_TAGS           0\n",
       "word_char_LU             0\n",
       "MALE_FEM              1144\n",
       "MALE_PIC              1144\n",
       "FEM_PIC               1144\n",
       "dtype: int64"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kivake.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shash\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py:4517: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().fillna(\n"
     ]
    }
   ],
   "source": [
    "fill_values = {'ORIGINAL_LANGUAGE' : 'MISSING', 'FEM_COUNT' : 0, 'MALE_COUNT' : 0,'PIC_TRUE_COUNT' : 0, 'PIC_FALSE_COUNT' : 0,'ANY_FEM' : 0,'ANY_MALE' : 0,'COUNTRY_CODE':'MISSING', 'MALE_FEM':0,'MALE_PIC':0,'FEM_PIC':0}\n",
    "kivake.fillna(value = fill_values, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                count      mean\n",
      "ACTIVITY_NAME                                  \n",
      "Agriculture                      2283  0.833552\n",
      "Animal Sales                      179  0.743017\n",
      "Bakery                             52  0.653846\n",
      "Beauty Salon                      700  0.652857\n",
      "Beverages                          68  0.735294\n",
      "Butcher Shop                      294  0.598639\n",
      "Cattle                            113  0.769912\n",
      "Cereals                          2689  0.732614\n",
      "Charcoal Sales                    343  0.760933\n",
      "Cloth & Dressmaking Supplies       20  0.650000\n",
      "Clothing                          342  0.903509\n",
      "Clothing Sales                   1457  0.636925\n",
      "Construction                       48  0.895833\n",
      "Construction Supplies              50  0.760000\n",
      "Cosmetics Sales                   208  0.634615\n",
      "Crafts                             45  0.977778\n",
      "Dairy                            2669  0.826527\n",
      "Education provider                 69  1.000000\n",
      "Embroidery                          5  0.800000\n",
      "Farm Supplies                     230  0.756522\n",
      "Farming                         19741  0.822197\n",
      "Fish Selling                      407  0.778870\n",
      "Fishing                             6  0.833333\n",
      "Food                              552  0.798913\n",
      "Food Market                       183  0.830601\n",
      "Food Production/Sales             352  0.823864\n",
      "Food Stall                        434  0.829493\n",
      "Fruits & Vegetables              1532  0.845953\n",
      "Furniture Making                   73  0.972603\n",
      "General Store                    2511  0.586619\n",
      "Grocery Store                     891  0.809203\n",
      "Higher education costs            191  0.926702\n",
      "Home Appliances                   199  1.000000\n",
      "Home Energy                      1786  1.000000\n",
      "Home Products Sales               171  0.619883\n",
      "Livestock                         314  0.856688\n",
      "Manufacturing                      25  1.000000\n",
      "Motorcycle Transport             1417  0.474947\n",
      "Personal Expenses                  33  0.939394\n",
      "Personal Housing Expenses          49  0.959184\n",
      "Personal Medical Expenses          32  1.000000\n",
      "Personal Products Sales            19  0.684211\n",
      "Pigs                               50  0.800000\n",
      "Poultry                          1164  0.909794\n",
      "Primary/secondary school costs    668  1.000000\n",
      "Restaurant                        260  0.626923\n",
      "Retail                           1628  0.653563\n",
      "Rickshaw                           35  0.657143\n",
      "Services                          466  0.742489\n",
      "Sewing                             23  0.869565\n",
      "Shoe Sales                        189  0.571429\n",
      "Tailoring                         679  0.837997\n",
      "Taxi                               64  0.484375\n",
      "Transportation                    146  0.595890\n",
      "Used Clothing                     389  0.789203\n",
      "Weaving                            44  1.000000\n",
      "miscellaneous                    2583  0.726287\n",
      "                count      mean\n",
      "SECTOR_NAME                    \n",
      "Agriculture     26810  0.826632\n",
      "Arts              121  0.983471\n",
      "Clothing         2232  0.707437\n",
      "Construction      372  0.854839\n",
      "Education         929  0.984930\n",
      "Entertainment      17  1.000000\n",
      "Food             7956  0.772247\n",
      "Health            167  1.000000\n",
      "Housing           201  0.656716\n",
      "Manufacturing     189  0.989418\n",
      "Personal Use     2033  0.997541\n",
      "Retail           5849  0.618396\n",
      "Services         2616  0.740443\n",
      "Transportation   1662  0.489771\n",
      "Wholesale          16  0.937500\n",
      "              count      mean\n",
      "COUNTRY_CODE                 \n",
      "KE            51170  0.784659\n",
      "                    count      mean\n",
      "REPAYMENT_INTERVAL                 \n",
      "bullet               7903  0.839048\n",
      "irregular             400  0.930000\n",
      "monthly             42867  0.773275\n",
      "                    count      mean\n",
      "DISTRIBUTION_MODEL                 \n",
      "direct                907  1.000000\n",
      "field_partner       50263  0.780773\n",
      "       count      mean\n",
      "month                 \n",
      "0       4379  0.755195\n",
      "1       9213  0.789645\n",
      "2       7693  0.878591\n",
      "3       4907  0.835949\n",
      "4       4682  0.715933\n",
      "5       4623  0.724854\n",
      "6       4180  0.738038\n",
      "7       4062  0.726243\n",
      "8       3610  0.778116\n",
      "9       3821  0.827270\n"
     ]
    }
   ],
   "source": [
    "catcols = ['ORIGINAL_LANGUAGE', 'ACTIVITY_NAME', 'SECTOR_NAME', 'COUNTRY_CODE', 'REPAYMENT_INTERVAL', 'DISTRIBUTION_MODEL', 'month']\n",
    "\n",
    "for i in range(1,len(catcols)):\n",
    "    print(kivake.groupby(catcols[i], dropna=False)['STATUS'].agg(['count', 'mean']))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "kivake_dummies = pd.get_dummies(kivake, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51170, 99)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kivake_dummies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    40151\n",
       "0    11019\n",
       "Name: STATUS, dtype: int64"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kivake_dummies['STATUS'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LOAN_ID', 'ORIGINAL_LANGUAGE', 'LOAN_AMOUNT', 'STATUS',\n",
       "       'ACTIVITY_NAME', 'SECTOR_NAME', 'COUNTRY_CODE', 'LENDER_TERM',\n",
       "       'REPAYMENT_INTERVAL', 'DISTRIBUTION_MODEL', 'word_count_DT',\n",
       "       'word_count_TAGS', 'word_count_LU', 'char_count_DT', 'char_count_TAGS',\n",
       "       'char_count_LU', 'month', 'FEM_COUNT', 'MALE_COUNT', 'PIC_TRUE_COUNT',\n",
       "       'PIC_FALSE_COUNT', 'ANY_FEM', 'ANY_MALE', 'word_char_DT',\n",
       "       'word_char_TAGS', 'word_char_LU', 'MALE_FEM', 'MALE_PIC', 'FEM_PIC'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kivake.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "### USE THIS FOR STREAMLIT WITHOUT DUMMY VARIABLES\n",
    "\n",
    "#Creating X, y and test-train split\n",
    "X = kivake[['LOAN_AMOUNT', 'word_count_TAGS', 'LENDER_TERM',\n",
    "       'word_count_LU', 'char_count_DT', 'char_count_TAGS', 'char_count_LU',\n",
    "       'month', 'FEM_COUNT', 'MALE_COUNT','PIC_TRUE_COUNT', 'PIC_FALSE_COUNT',\n",
    "       'ANY_FEM', 'ANY_MALE', 'word_char_DT', 'word_char_TAGS', 'word_char_LU',\n",
    "       'MALE_FEM', 'MALE_PIC', 'FEM_PIC']]\n",
    "y = kivake['STATUS']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        LOAN_AMOUNT  word_count_TAGS  LENDER_TERM  word_count_LU  \\\n",
      "mean     487.191225         4.009322    13.155794      11.923529   \n",
      "median   400.000000         4.000000    14.000000      11.000000   \n",
      "\n",
      "        char_count_DT  char_count_TAGS  char_count_LU     month  FEM_COUNT  \\\n",
      "mean        645.08677        36.825933      59.131952  3.868399   1.417862   \n",
      "median      573.00000        35.000000      51.000000  3.000000   1.000000   \n",
      "\n",
      "        MALE_COUNT  PIC_TRUE_COUNT  PIC_FALSE_COUNT  ANY_FEM  ANY_MALE  \\\n",
      "mean      2.194118        2.193942         0.000176  0.76154  0.977643   \n",
      "median    1.000000        1.000000         0.000000  1.00000  1.000000   \n",
      "\n",
      "         word_char_DT  word_char_TAGS  word_char_LU  MALE_FEM   MALE_PIC  \\\n",
      "mean    104776.674243       231.40469    942.901583  9.449912  16.105472   \n",
      "median   68442.000000       140.00000    561.000000  1.000000   1.000000   \n",
      "\n",
      "         FEM_PIC  \n",
      "mean    9.449248  \n",
      "median  1.000000  \n",
      "        LOAN_AMOUNT  word_count_TAGS  LENDER_TERM  word_count_LU  \\\n",
      "mean     487.191225         4.009322    13.155794      11.923529   \n",
      "median   400.000000         4.000000    14.000000      11.000000   \n",
      "\n",
      "        char_count_DT  char_count_TAGS  char_count_LU     month  FEM_COUNT  \\\n",
      "mean        645.08677        36.825933      59.131952  3.868399   1.417862   \n",
      "median      573.00000        35.000000      51.000000  3.000000   1.000000   \n",
      "\n",
      "        MALE_COUNT  PIC_TRUE_COUNT  PIC_FALSE_COUNT  ANY_FEM  ANY_MALE  \\\n",
      "mean      2.194118        2.193942         0.000176  0.76154  0.977643   \n",
      "median    1.000000        1.000000         0.000000  1.00000  1.000000   \n",
      "\n",
      "         word_char_DT  word_char_TAGS  word_char_LU  MALE_FEM   MALE_PIC  \\\n",
      "mean    104776.674243       231.40469    942.901583  9.449912  16.105472   \n",
      "median   68442.000000       140.00000    561.000000  1.000000   1.000000   \n",
      "\n",
      "         FEM_PIC  \n",
      "mean    9.449248  \n",
      "median  1.000000  \n",
      "        LOAN_AMOUNT  word_count_TAGS  LENDER_TERM  word_count_LU  \\\n",
      "mean     487.191225         4.009322    13.155794      11.923529   \n",
      "median   400.000000         4.000000    14.000000      11.000000   \n",
      "\n",
      "        char_count_DT  char_count_TAGS  char_count_LU     month  FEM_COUNT  \\\n",
      "mean        645.08677        36.825933      59.131952  3.868399   1.417862   \n",
      "median      573.00000        35.000000      51.000000  3.000000   1.000000   \n",
      "\n",
      "        MALE_COUNT  PIC_TRUE_COUNT  PIC_FALSE_COUNT  ANY_FEM  ANY_MALE  \\\n",
      "mean      2.194118        2.193942         0.000176  0.76154  0.977643   \n",
      "median    1.000000        1.000000         0.000000  1.00000  1.000000   \n",
      "\n",
      "         word_char_DT  word_char_TAGS  word_char_LU  MALE_FEM   MALE_PIC  \\\n",
      "mean    104776.674243       231.40469    942.901583  9.449912  16.105472   \n",
      "median   68442.000000       140.00000    561.000000  1.000000   1.000000   \n",
      "\n",
      "         FEM_PIC  \n",
      "mean    9.449248  \n",
      "median  1.000000  \n",
      "        LOAN_AMOUNT  word_count_TAGS  LENDER_TERM  word_count_LU  \\\n",
      "mean     487.191225         4.009322    13.155794      11.923529   \n",
      "median   400.000000         4.000000    14.000000      11.000000   \n",
      "\n",
      "        char_count_DT  char_count_TAGS  char_count_LU     month  FEM_COUNT  \\\n",
      "mean        645.08677        36.825933      59.131952  3.868399   1.417862   \n",
      "median      573.00000        35.000000      51.000000  3.000000   1.000000   \n",
      "\n",
      "        MALE_COUNT  PIC_TRUE_COUNT  PIC_FALSE_COUNT  ANY_FEM  ANY_MALE  \\\n",
      "mean      2.194118        2.193942         0.000176  0.76154  0.977643   \n",
      "median    1.000000        1.000000         0.000000  1.00000  1.000000   \n",
      "\n",
      "         word_char_DT  word_char_TAGS  word_char_LU  MALE_FEM   MALE_PIC  \\\n",
      "mean    104776.674243       231.40469    942.901583  9.449912  16.105472   \n",
      "median   68442.000000       140.00000    561.000000  1.000000   1.000000   \n",
      "\n",
      "         FEM_PIC  \n",
      "mean    9.449248  \n",
      "median  1.000000  \n",
      "        LOAN_AMOUNT  word_count_TAGS  LENDER_TERM  word_count_LU  \\\n",
      "mean     487.191225         4.009322    13.155794      11.923529   \n",
      "median   400.000000         4.000000    14.000000      11.000000   \n",
      "\n",
      "        char_count_DT  char_count_TAGS  char_count_LU     month  FEM_COUNT  \\\n",
      "mean        645.08677        36.825933      59.131952  3.868399   1.417862   \n",
      "median      573.00000        35.000000      51.000000  3.000000   1.000000   \n",
      "\n",
      "        MALE_COUNT  PIC_TRUE_COUNT  PIC_FALSE_COUNT  ANY_FEM  ANY_MALE  \\\n",
      "mean      2.194118        2.193942         0.000176  0.76154  0.977643   \n",
      "median    1.000000        1.000000         0.000000  1.00000  1.000000   \n",
      "\n",
      "         word_char_DT  word_char_TAGS  word_char_LU  MALE_FEM   MALE_PIC  \\\n",
      "mean    104776.674243       231.40469    942.901583  9.449912  16.105472   \n",
      "median   68442.000000       140.00000    561.000000  1.000000   1.000000   \n",
      "\n",
      "         FEM_PIC  \n",
      "mean    9.449248  \n",
      "median  1.000000  \n",
      "        LOAN_AMOUNT  word_count_TAGS  LENDER_TERM  word_count_LU  \\\n",
      "mean     487.191225         4.009322    13.155794      11.923529   \n",
      "median   400.000000         4.000000    14.000000      11.000000   \n",
      "\n",
      "        char_count_DT  char_count_TAGS  char_count_LU     month  FEM_COUNT  \\\n",
      "mean        645.08677        36.825933      59.131952  3.868399   1.417862   \n",
      "median      573.00000        35.000000      51.000000  3.000000   1.000000   \n",
      "\n",
      "        MALE_COUNT  PIC_TRUE_COUNT  PIC_FALSE_COUNT  ANY_FEM  ANY_MALE  \\\n",
      "mean      2.194118        2.193942         0.000176  0.76154  0.977643   \n",
      "median    1.000000        1.000000         0.000000  1.00000  1.000000   \n",
      "\n",
      "         word_char_DT  word_char_TAGS  word_char_LU  MALE_FEM   MALE_PIC  \\\n",
      "mean    104776.674243       231.40469    942.901583  9.449912  16.105472   \n",
      "median   68442.000000       140.00000    561.000000  1.000000   1.000000   \n",
      "\n",
      "         FEM_PIC  \n",
      "mean    9.449248  \n",
      "median  1.000000  \n",
      "        LOAN_AMOUNT  word_count_TAGS  LENDER_TERM  word_count_LU  \\\n",
      "mean     487.191225         4.009322    13.155794      11.923529   \n",
      "median   400.000000         4.000000    14.000000      11.000000   \n",
      "\n",
      "        char_count_DT  char_count_TAGS  char_count_LU     month  FEM_COUNT  \\\n",
      "mean        645.08677        36.825933      59.131952  3.868399   1.417862   \n",
      "median      573.00000        35.000000      51.000000  3.000000   1.000000   \n",
      "\n",
      "        MALE_COUNT  PIC_TRUE_COUNT  PIC_FALSE_COUNT  ANY_FEM  ANY_MALE  \\\n",
      "mean      2.194118        2.193942         0.000176  0.76154  0.977643   \n",
      "median    1.000000        1.000000         0.000000  1.00000  1.000000   \n",
      "\n",
      "         word_char_DT  word_char_TAGS  word_char_LU  MALE_FEM   MALE_PIC  \\\n",
      "mean    104776.674243       231.40469    942.901583  9.449912  16.105472   \n",
      "median   68442.000000       140.00000    561.000000  1.000000   1.000000   \n",
      "\n",
      "         FEM_PIC  \n",
      "mean    9.449248  \n",
      "median  1.000000  \n",
      "        LOAN_AMOUNT  word_count_TAGS  LENDER_TERM  word_count_LU  \\\n",
      "mean     487.191225         4.009322    13.155794      11.923529   \n",
      "median   400.000000         4.000000    14.000000      11.000000   \n",
      "\n",
      "        char_count_DT  char_count_TAGS  char_count_LU     month  FEM_COUNT  \\\n",
      "mean        645.08677        36.825933      59.131952  3.868399   1.417862   \n",
      "median      573.00000        35.000000      51.000000  3.000000   1.000000   \n",
      "\n",
      "        MALE_COUNT  PIC_TRUE_COUNT  PIC_FALSE_COUNT  ANY_FEM  ANY_MALE  \\\n",
      "mean      2.194118        2.193942         0.000176  0.76154  0.977643   \n",
      "median    1.000000        1.000000         0.000000  1.00000  1.000000   \n",
      "\n",
      "         word_char_DT  word_char_TAGS  word_char_LU  MALE_FEM   MALE_PIC  \\\n",
      "mean    104776.674243       231.40469    942.901583  9.449912  16.105472   \n",
      "median   68442.000000       140.00000    561.000000  1.000000   1.000000   \n",
      "\n",
      "         FEM_PIC  \n",
      "mean    9.449248  \n",
      "median  1.000000  \n",
      "        LOAN_AMOUNT  word_count_TAGS  LENDER_TERM  word_count_LU  \\\n",
      "mean     487.191225         4.009322    13.155794      11.923529   \n",
      "median   400.000000         4.000000    14.000000      11.000000   \n",
      "\n",
      "        char_count_DT  char_count_TAGS  char_count_LU     month  FEM_COUNT  \\\n",
      "mean        645.08677        36.825933      59.131952  3.868399   1.417862   \n",
      "median      573.00000        35.000000      51.000000  3.000000   1.000000   \n",
      "\n",
      "        MALE_COUNT  PIC_TRUE_COUNT  PIC_FALSE_COUNT  ANY_FEM  ANY_MALE  \\\n",
      "mean      2.194118        2.193942         0.000176  0.76154  0.977643   \n",
      "median    1.000000        1.000000         0.000000  1.00000  1.000000   \n",
      "\n",
      "         word_char_DT  word_char_TAGS  word_char_LU  MALE_FEM   MALE_PIC  \\\n",
      "mean    104776.674243       231.40469    942.901583  9.449912  16.105472   \n",
      "median   68442.000000       140.00000    561.000000  1.000000   1.000000   \n",
      "\n",
      "         FEM_PIC  \n",
      "mean    9.449248  \n",
      "median  1.000000  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var_list = ['FEM_COUNT', 'MALE_COUNT', 'PIC_TRUE_COUNT', 'PIC_FALSE_COUNT', 'ANY_FEM', 'ANY_MALE', 'MALE_FEM', 'MALE_PIC', 'FEM_PIC']\n",
    "\n",
    "#[print(X.groupby(i).agg(['mean', 'median'])) for i in var_list\n",
    " \n",
    "[print(X.agg(['mean', 'median'])) for i in var_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Perform test-train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state =42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOT FOR STREAMLIT since based on dummies\n",
    "#Creating X, y and test-train split\n",
    "X = kivake_dummies.drop(columns = ['STATUS'])\n",
    "y = kivake_dummies['STATUS']\n",
    "\n",
    "#Perform test-train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state =42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a pipeline with GB\n",
    "pipe_gb = Pipeline([\n",
    "    (\"sc\", StandardScaler()),\n",
    "    (\"gb\", GradientBoostingClassifier(n_estimators=50, \n",
    "                        min_samples_split = 100, \n",
    "                        min_samples_leaf = 50, \n",
    "                        max_depth=5,\n",
    "                        max_features='sqrt',\n",
    "                        learning_rate = 0.1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8464184277040936 0.8416321425779724 0.8428484977076482\n"
     ]
    }
   ],
   "source": [
    "#Piping & scoring\n",
    "pipe_gb.fit(X_train, y_train)\n",
    "print(pipe_gb.score(X_train, y_train), pipe_gb.score(X_test, y_test),  \n",
    "      cross_val_score(pipe_gb, X_train, y_train, cv = 5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put the two functions above together, using 'write binary' permissions\n",
    "pickle.dump(pipe_gb, open('pipe.p', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "      <th>feature_names</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.438861</td>\n",
       "      <td>LOAN_AMOUNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.080230</td>\n",
       "      <td>LENDER_TERM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.067509</td>\n",
       "      <td>char_count_TAGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.057193</td>\n",
       "      <td>month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.053809</td>\n",
       "      <td>ANY_FEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.051371</td>\n",
       "      <td>word_count_TAGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.047273</td>\n",
       "      <td>word_char_TAGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.041036</td>\n",
       "      <td>FEM_PIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.040362</td>\n",
       "      <td>MALE_FEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.030167</td>\n",
       "      <td>FEM_COUNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.023201</td>\n",
       "      <td>word_char_DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.016473</td>\n",
       "      <td>word_char_LU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.015167</td>\n",
       "      <td>PIC_TRUE_COUNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.010233</td>\n",
       "      <td>char_count_DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.008624</td>\n",
       "      <td>MALE_COUNT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008433</td>\n",
       "      <td>word_count_LU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.007181</td>\n",
       "      <td>char_count_LU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.002789</td>\n",
       "      <td>MALE_PIC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000086</td>\n",
       "      <td>ANY_MALE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>PIC_FALSE_COUNT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    importance    feature_names\n",
       "0     0.438861      LOAN_AMOUNT\n",
       "2     0.080230      LENDER_TERM\n",
       "5     0.067509  char_count_TAGS\n",
       "7     0.057193            month\n",
       "12    0.053809          ANY_FEM\n",
       "1     0.051371  word_count_TAGS\n",
       "15    0.047273   word_char_TAGS\n",
       "19    0.041036          FEM_PIC\n",
       "17    0.040362         MALE_FEM\n",
       "8     0.030167        FEM_COUNT\n",
       "14    0.023201     word_char_DT\n",
       "16    0.016473     word_char_LU\n",
       "10    0.015167   PIC_TRUE_COUNT\n",
       "4     0.010233    char_count_DT\n",
       "9     0.008624       MALE_COUNT\n",
       "3     0.008433    word_count_LU\n",
       "6     0.007181    char_count_LU\n",
       "18    0.002789         MALE_PIC\n",
       "13    0.000086         ANY_MALE\n",
       "11    0.000000  PIC_FALSE_COUNT"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame({'importance' : pipe_gb.named_steps['gb'].feature_importances_, 'feature_names' : X_train.columns}).sort_values(by='importance', ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LOAN_AMOUNT', 'word_count_TAGS', 'LENDER_TERM', 'word_count_LU',\n",
       "       'char_count_DT', 'char_count_TAGS', 'char_count_LU', 'month',\n",
       "       'FEM_COUNT', 'MALE_COUNT', 'PIC_TRUE_COUNT', 'PIC_FALSE_COUNT',\n",
       "       'ANY_FEM', 'ANY_MALE', 'word_char_DT', 'word_char_TAGS', 'word_char_LU',\n",
       "       'MALE_FEM', 'MALE_PIC', 'FEM_PIC'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale features\n",
    "sc = StandardScaler()\n",
    "X_train_sc = sc.fit_transform(X_train)\n",
    "X_test_sc = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8541053235010553 0.8503087626045494 0.8494670133908642\n"
     ]
    }
   ],
   "source": [
    "#RandomForestClassifier(bootstrap=False, max_features='sqrt', min_samples_leaf=2,\n",
    "#                       min_samples_split=15, n_estimators=23)\n",
    "\n",
    "gb = GradientBoostingClassifier(n_estimators=100, \n",
    "                        min_samples_split = 100, \n",
    "                        min_samples_leaf = 50, \n",
    "                        max_depth=5,\n",
    "                        max_features='sqrt',\n",
    "                        learning_rate = 0.1)\n",
    "gb.fit(X_train_sc, y_train)\n",
    "print(gb.score(X_train_sc, y_train), gb.score(X_test_sc, y_test),  \n",
    "      cross_val_score(rf, X_train_sc, y_train, cv = 5).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_cols = pd.DataFrame({'importance' : gb.feature_importances_, 'feature_names' : X_train.columns}).sort_values(by='importance', ascending=False).head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 2)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_cols.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "bott_cols_df = pd.DataFrame(top_cols.tail(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "bott_col_list = bott_cols_df['feature_names']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80            SECTOR_NAME_Retail\n",
       "19                      MALE_PIC\n",
       "5                  char_count_DT\n",
       "2                  word_count_DT\n",
       "82    SECTOR_NAME_Transportation\n",
       "15                  word_char_DT\n",
       "7                  char_count_LU\n",
       "50     ACTIVITY_NAME_Home Energy\n",
       "17                  word_char_LU\n",
       "11                PIC_TRUE_COUNT\n",
       "85    REPAYMENT_INTERVAL_monthly\n",
       "4                  word_count_LU\n",
       "73         SECTOR_NAME_Education\n",
       "78     SECTOR_NAME_Manufacturing\n",
       "14                      ANY_MALE\n",
       "Name: feature_names, dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bott_col_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_score = pd.DataFrame(gb.predict_proba(X_train_sc))\n",
    "X_train_score['LOAN_ID'] = kivake['LOAN_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_score = gb.predict_proba(X_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>LOAN_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.110239</td>\n",
       "      <td>0.889761</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.394194</td>\n",
       "      <td>0.605806</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.139473</td>\n",
       "      <td>0.860527</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.220802</td>\n",
       "      <td>0.779198</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.219644</td>\n",
       "      <td>0.780356</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38372</th>\n",
       "      <td>0.004634</td>\n",
       "      <td>0.995366</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38373</th>\n",
       "      <td>0.055889</td>\n",
       "      <td>0.944111</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38374</th>\n",
       "      <td>0.007728</td>\n",
       "      <td>0.992272</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38375</th>\n",
       "      <td>0.252462</td>\n",
       "      <td>0.747538</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38376</th>\n",
       "      <td>0.304209</td>\n",
       "      <td>0.695791</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38377 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1  LOAN_ID\n",
       "0      0.110239  0.889761      NaN\n",
       "1      0.394194  0.605806      NaN\n",
       "2      0.139473  0.860527      NaN\n",
       "3      0.220802  0.779198      NaN\n",
       "4      0.219644  0.780356      NaN\n",
       "...         ...       ...      ...\n",
       "38372  0.004634  0.995366      NaN\n",
       "38373  0.055889  0.944111      NaN\n",
       "38374  0.007728  0.992272      NaN\n",
       "38375  0.252462  0.747538      NaN\n",
       "38376  0.304209  0.695791      NaN\n",
       "\n",
       "[38377 rows x 3 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
